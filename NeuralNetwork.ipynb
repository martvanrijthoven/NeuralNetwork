{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import MNIST\n",
    "import _pickle as cPickle\n",
    "import gzip\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_diff(x):\n",
    "    return (x > 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_diff(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_diff(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "def one_hot_encoding(ys, outputs=10):\n",
    "    lbl = np.zeros((len(ys),outputs))\n",
    "    for l in range(len(ys)):\n",
    "        lbl[l][ys[l]] = 1\n",
    "    return lbl\n",
    "\n",
    "def show_image(norm_pixels, label=None):\n",
    "    if label is not None:\n",
    "        plt.title('Label is {label}'.format(label=np.argmax(label)))  \n",
    "\n",
    "    img = np.array(norm_pixels*255, dtype='uint8').reshape((28,28))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "class BatchGenerator():\n",
    "    def __init__(self, batch_size):\n",
    "        mnist = gzip.open('./data/mnist.pkl.gz', 'rb')\n",
    "        self.training_data, self.validation_data, self. test_data = \\\n",
    "            cPickle.load(mnist,encoding='iso-8859-1')\n",
    "            \n",
    "        self.training_data = list(zip(self.training_data[0],one_hot_encoding(self.training_data[1])))\n",
    "        self.validation_data = (self.validation_data[0],one_hot_encoding(self.validation_data[1]))\n",
    "        self.test_data = (self.test_data[0],one_hot_encoding(self.test_data[1]))\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.batch_index = 0\n",
    "        self.reset()\n",
    "\n",
    "    def _shuffle(self):\n",
    "        self.batch_index = 0\n",
    "        random.shuffle(self.training_data)\n",
    " \n",
    "    def batch(self): \n",
    "        \n",
    "        x_batch, y_batch = zip(*self.training_data[self.batch_index:self.batch_index+self.batch_size])\n",
    "        \n",
    "        self.batch_index += self.batch_size\n",
    "        \n",
    "        if self.batch_index >= len(self.training_data):\n",
    "            self.reset()\n",
    "\n",
    "        return np.array(x_batch), np.array(y_batch)\n",
    "    \n",
    "    def get_epochs(self):\n",
    "        self.training_data[0]/self.batch_size\n",
    "        \n",
    "    def reset(self):\n",
    "        self._shuffle()\n",
    "        self.batch_index = 0\n",
    "    \n",
    "class NeuralNetwork():\n",
    "    def __init__(self, layers):\n",
    "        # layers\n",
    "        self.layers = layers\n",
    "        \n",
    "        # number of layers\n",
    "        self.n_layers = len(layers)\n",
    "\n",
    "        # init weights\n",
    "        self.weights = []\n",
    "        for i in range(self.n_layers - 1):\n",
    "            self.weights.append(0.005*np.random.rand(layers[i], layers[i + 1]))\n",
    "            \n",
    "        # init biases\n",
    "        self.biases = [0.005*np.random.rand(b) for b in layers[1:]]\n",
    "        \n",
    "\n",
    "    def _forward_pass(self, input, verbose=False):\n",
    "        inputs = []\n",
    "        activations = [input]\n",
    "        for i in range(self.n_layers - 1):\n",
    "            inputs.append(activations[i].dot(self.weights[i]) + self.biases[i])\n",
    "            activations.append(relu(inputs[-1]))\n",
    "        return {'inputs': inputs, 'activations': activations}\n",
    "\n",
    "    def _backward_pass(self, forward, y): \n",
    "        \n",
    "        delta_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        delta_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        # error output layer\n",
    "        error = (forward['activations'][-1] - y) * relu_diff(forward['inputs'][-1])\n",
    "        delta_w[-1] += forward['activations'][-2].transpose().dot(error)\n",
    "        delta_b[-1] += np.sum(error, axis=0)\n",
    "        \n",
    "        # error hidden layers\n",
    "        for l in range(self.n_layers - 3, -1, -1):\n",
    "            error = error.dot(self.weights[l + 1].transpose())*relu_diff(forward['inputs'][l])\n",
    "            delta_w[l] += forward['activations'][l].transpose().dot(error)\n",
    "            delta_b[l] += np.sum(error, axis=0)\n",
    "            \n",
    "        return delta_w, delta_b\n",
    "    \n",
    "    def train(self, batch_generator, learning_rate = 0.02, epochs=60000):  \n",
    "        \n",
    "        for e in range(epochs):\n",
    "            # get batch\n",
    "            x_batch, y_batch = batch_generator.batch()\n",
    " \n",
    "            # get deltas\n",
    "            delta_w, delta_b = self._backward_pass(self._forward_pass(x_batch), y_batch)\n",
    "            \n",
    "            #update weights and biases\n",
    "            for l in range(self.n_layers - 1):\n",
    "                self.weights[l] -= learning_rate * delta_w[l] \n",
    "                self.biases[l] -= learning_rate * delta_b[l]  \n",
    "\n",
    "        \n",
    "    def inference(self,input):\n",
    "        return np.argmax(self._forward_pass(input)['activations'][-1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 970    0    1    1    0    0    4    2    2    0]\n",
      " [   0 1123    4    4    0    1    1    0    2    0]\n",
      " [   9    1  988    6    9    0    2   10    7    0]\n",
      " [   1    0   14  971    0    4    0   10    2    8]\n",
      " [   0    0    4    0  964    0    3    1    0   10]\n",
      " [   8    2    0   24    2  834    9    6    2    5]\n",
      " [   6    2    3    0    8    5  933    0    1    0]\n",
      " [   2   12   19    1    5    1    1  976    2    9]\n",
      " [  11    4    6   16   14    4   11   11  890    7]\n",
      " [   4    6    0   12   50    3    1    9    0  924]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97       980\n",
      "          1       0.98      0.99      0.98      1135\n",
      "          2       0.95      0.96      0.95      1032\n",
      "          3       0.94      0.96      0.95      1010\n",
      "          4       0.92      0.98      0.95       982\n",
      "          5       0.98      0.93      0.96       892\n",
      "          6       0.97      0.97      0.97       958\n",
      "          7       0.95      0.95      0.95      1028\n",
      "          8       0.98      0.91      0.95       974\n",
      "          9       0.96      0.92      0.94      1009\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = BatchGenerator(1)\n",
    "nn = NeuralNetwork([784,60,10])\n",
    "nn.train(batch_generator)\n",
    "\n",
    "x_test, y_test = batch_generator.test_data\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    o = nn.inference(np.atleast_2d(x_test[i]))\n",
    "    predictions.append(o)\n",
    "    true_labels.append(np.argmax(y_test[i]))\n",
    "    \n",
    "    \n",
    "print(confusion_matrix(true_labels,predictions))\n",
    "print(classification_report(true_labels,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
